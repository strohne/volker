---
title: "Reliability and classification performance indicators"
output: volker::html_report
vignette: >
  %\VignetteIndexEntry{Reliability}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = F)

library(tidyverse)
library(volker)
```

```{r}

# Load data 
data <- volker::chatgpt

# Code some data for reliability calculations
# First, add a colder column to the already existing example data
data_coder1 <- data |> 
  mutate(coder = "c1") %>% 
  mutate(across(starts_with("cg_act_"), ~ ifelse(is.na(.), FALSE, TRUE))) %>% 
  select(case, coder, starts_with("cg_act_"))
  
# Second, code the data using a simple dictionary approach
# Be aware, this is not exactly a procedure of manual content analysis as 
# assumed by the reliability calculation algorithms. Just for example purposes.
data_coder2 <- data |> 
  mutate(cg_activities = tolower(cg_activities)) |> 
  mutate(
    cg_act_write = str_detect(cg_activities, "text|write|formulate|translate|create"),
    cg_act_test = str_detect(cg_activities, "test|fun|experiment"),
    cg_act_search = str_detect(cg_activities, "search|information|question|answer"),
    coder="c2"
  ) %>% 
  select(case, coder, starts_with("cg_act_"))

data_coded <- bind_rows(
  data_coder1,
  data_coder2
)


```


## Using report_counts()

```{r}

# TODO: Add confusion matrix or something similar
# TODO: Output agreement in plots / tables (c11 & c2, c1 only, c2 only)
report_counts(data_coded, cg_act_write, coder, ids = case, prop="cells", agree = "reli")
report_counts(data_coded, starts_with("cg_act_"), coder, ids = case, agree = "reliability")

```

## 1. Reliability for a single item
```{r}

agree_tab(data_coded, cg_act_write, coder, ids = case, method="reli")

```


## 2. Reliability for multiple items
```{r}

agree_tab(data_coded, starts_with("cg_act_"), coder, ids = case, method="reliability")

```



## 3. F1 for a single item
```{r}

agree_tab(data_coded, cg_act_write, coder, ids = case, method="classification")

```


## 4. F1 for multiple items
```{r}

agree_tab(data_coded, starts_with("topic_"), coder, ids = case, method="classification")

```


## 5. Choosing macro statistics vs. single categories
```{r}

# There are three cases to consider:
# - If you provide a category in the respective parameter,
#   results relate to this category. 
# - If you omit the parameter (or set it to null) and you have boolean values,
#   the TRUE category is automatically choosen.
# - Otherwise, macro statistics for precision, recall, and f1 are calculated by
#   averaging over the results of all categories. You will find the number of categories
#   in the result table.

# The following assumes that "no" is the target category of interest
# (although this is unlikely in real world scenarios)
data_coded %>% 
  mutate(across(starts_with("cg_act_"), ~ ifelse(., "yes", "no"))) %>% 
  agree_tab(starts_with("cg_act_"), coder, ids = case, method = "classification", category = "no")

```

